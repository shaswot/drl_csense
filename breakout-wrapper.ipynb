{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ff92c7-16da-4d92-99bf-95b053e08258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae3900d-b32b-49fe-9d4f-a5040e0655dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51e94f4d-0c59-42a5-ac7e-d81d796d3304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "873a9278-f8fb-4251-b5be-a7ebf4c6e0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 12:40:22.089646: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-12 12:40:22.142712: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-12 12:40:22.964367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e9bef7-a41e-4218-8b4d-c5762317f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f04c9cc5-23c1-435f-8853-deef5e4572d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaeaf7eb-dc80-429f-84c8-ad0514b4063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.atari_wrappers import StickyActionEnv, NoopResetEnv, MaxAndSkipEnv, EpisodicLifeEnv, FireResetEnv, WarpFrame, ClipRewardEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e956ceda-da1f-46e5-85b1-fb26c30e6426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, Optional, Type, Union\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv, VecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb7691a4-9baf-4c6e-8080-c6283b76de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpsideDown(gym.ObservationWrapper[np.ndarray, int, np.ndarray]):\n",
    "    def __init__(self, env: gym.Env, width: int = 84, height: int = 84) -> None:\n",
    "        super().__init__(env)\n",
    "    def observation(self, frame: np.ndarray) -> np.ndarray:\n",
    "        return np.flipud(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c51b960c-eecd-46bc-a24d-431d8e5bbfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAtariWrapper(gym.Wrapper[np.ndarray, int, np.ndarray, int]):\n",
    "    \"\"\"\n",
    "    Atari 2600 preprocessings\n",
    "\n",
    "    Specifically:\n",
    "\n",
    "    * Noop reset: obtain initial state by taking random number of no-ops on reset.\n",
    "    * Frame skipping: 4 by default\n",
    "    * Max-pooling: most recent two observations\n",
    "    * Termination signal when a life is lost.\n",
    "    * Resize to a square image: 84x84 by default\n",
    "    * Grayscale observation\n",
    "    * Clip reward to {-1, 0, 1}\n",
    "    * Sticky actions: disabled by default\n",
    "\n",
    "    See https://danieltakeshi.github.io/2016/11/25/frame-skipping-and-preprocessing-for-deep-q-networks-on-atari-2600-games/\n",
    "    for a visual explanation.\n",
    "\n",
    "    .. warning::\n",
    "        Use this wrapper only with Atari v4 without frame skip: ``env_id = \"*NoFrameskip-v4\"``.\n",
    "\n",
    "    :param env: Environment to wrap\n",
    "    :param noop_max: Max number of no-ops\n",
    "    :param frame_skip: Frequency at which the agent experiences the game.\n",
    "        This correspond to repeating the action ``frame_skip`` times.\n",
    "    :param screen_size: Resize Atari frame\n",
    "    :param terminal_on_life_loss: If True, then step() returns done=True whenever a life is lost.\n",
    "    :param clip_reward: If True (default), the reward is clip to {-1, 0, 1} depending on its sign.\n",
    "    :param action_repeat_probability: Probability of repeating the last action\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: gym.Env,\n",
    "        noop_max: int = 30,\n",
    "        frame_skip: int = 4,\n",
    "        screen_size: int = 84,\n",
    "        terminal_on_life_loss: bool = True,\n",
    "        clip_reward: bool = True,\n",
    "        action_repeat_probability: float = 0.0,\n",
    "    ) -> None:\n",
    "        if action_repeat_probability > 0.0:\n",
    "            env = StickyActionEnv(env, action_repeat_probability)\n",
    "        if noop_max > 0:\n",
    "            env = NoopResetEnv(env, noop_max=noop_max)\n",
    "        # frame_skip=1 is the same as no frame-skip (action repeat)\n",
    "        if frame_skip > 1:\n",
    "            env = MaxAndSkipEnv(env, skip=frame_skip)\n",
    "        if terminal_on_life_loss:\n",
    "            env = EpisodicLifeEnv(env)\n",
    "        if \"FIRE\" in env.unwrapped.get_action_meanings():  # type: ignore[attr-defined]\n",
    "            env = FireResetEnv(env)\n",
    "        env = WarpFrame(env, width=screen_size, height=screen_size)\n",
    "        env = UpsideDown(env)\n",
    "        if clip_reward:\n",
    "            env = ClipRewardEnv(env)\n",
    "\n",
    "        super().__init__(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "043358cc-5374-4d0a-ad88-14e6dd106d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_my_atari_env(\n",
    "    env_id: Union[str, Callable[..., gym.Env]],\n",
    "    n_envs: int = 1,\n",
    "    seed: Optional[int] = None,\n",
    "    start_index: int = 0,\n",
    "    monitor_dir: Optional[str] = None,\n",
    "    wrapper_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    env_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    vec_env_cls: Optional[Union[Type[DummyVecEnv], Type[SubprocVecEnv]]] = None,\n",
    "    vec_env_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    monitor_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    ) -> VecEnv:\n",
    "    \"\"\"\n",
    "    Create a wrapped, monitored VecEnv for Atari.\n",
    "    It is a wrapper around ``make_vec_env`` that includes common preprocessing for Atari games.\n",
    "\n",
    "    :param env_id: either the env ID, the env class or a callable returning an env\n",
    "    :param n_envs: the number of environments you wish to have in parallel\n",
    "    :param seed: the initial seed for the random number generator\n",
    "    :param start_index: start rank index\n",
    "    :param monitor_dir: Path to a folder where the monitor files will be saved.\n",
    "        If None, no file will be written, however, the env will still be wrapped\n",
    "        in a Monitor wrapper to provide additional information about training.\n",
    "    :param wrapper_kwargs: Optional keyword argument to pass to the ``AtariWrapper``\n",
    "    :param env_kwargs: Optional keyword argument to pass to the env constructor\n",
    "    :param vec_env_cls: A custom ``VecEnv`` class constructor. Default: None.\n",
    "    :param vec_env_kwargs: Keyword arguments to pass to the ``VecEnv`` class constructor.\n",
    "    :param monitor_kwargs: Keyword arguments to pass to the ``Monitor`` class constructor.\n",
    "    :return: The wrapped environment\n",
    "    \"\"\"\n",
    "    return make_vec_env(\n",
    "        env_id,\n",
    "        n_envs=n_envs,\n",
    "        seed=seed,\n",
    "        start_index=start_index,\n",
    "        monitor_dir=monitor_dir,\n",
    "        wrapper_class=MyAtariWrapper,\n",
    "        env_kwargs=env_kwargs,\n",
    "        vec_env_cls=vec_env_cls,\n",
    "        vec_env_kwargs=vec_env_kwargs,\n",
    "        monitor_kwargs=monitor_kwargs,\n",
    "        wrapper_kwargs=wrapper_kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ea9240d-8d38-4c32-9c61-ea3d9f833559",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"Breakout-v4\"\n",
    "gif_folder = \"logfiles/gifs/\"\n",
    "models_folder = \"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2037790-a895-4428-841c-75cb44af2d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "envs = make_my_atari_env(env_id, n_envs=4, seed=0)\n",
    "envs = VecFrameStack(envs, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17f33bcb-904f-4195-8b8f-fb23ac6ac4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:364: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "obs = envs.reset()\n",
    "img = envs.render(mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c74057b-3dbf-43c9-a706-171292903164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fec8f909240>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.axis(False)\n",
    "plt.imshow(obs[3,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "686faa57-ef85-466e-976f-9b186f655ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 273      |\n",
      "|    ep_rew_mean        | 1.47     |\n",
      "| time/                 |          |\n",
      "|    fps                | 178      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.09    |\n",
      "|    explained_variance | 0.00382  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.151    |\n",
      "|    value_loss         | 0.194    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 284      |\n",
      "|    ep_rew_mean        | 1.74     |\n",
      "| time/                 |          |\n",
      "|    fps                | 198      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.2     |\n",
      "|    explained_variance | -0.222   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.00259 |\n",
      "|    value_loss         | 9.3e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 291      |\n",
      "|    ep_rew_mean        | 1.85     |\n",
      "| time/                 |          |\n",
      "|    fps                | 207      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.16    |\n",
      "|    explained_variance | -0.334   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -0.022   |\n",
      "|    value_loss         | 0.000601 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 290      |\n",
      "|    ep_rew_mean        | 1.86     |\n",
      "| time/                 |          |\n",
      "|    fps                | 212      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.04    |\n",
      "|    explained_variance | 0.000984 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.00968 |\n",
      "|    value_loss         | 0.108    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 289       |\n",
      "|    ep_rew_mean        | 1.87      |\n",
      "| time/                 |           |\n",
      "|    fps                | 216       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.05     |\n",
      "|    explained_variance | -0.000539 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 0.0405    |\n",
      "|    value_loss         | 0.144     |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = A2C(\"MlpPolicy\", envs, verbose=1)\n",
    "model.learn(total_timesteps=1E4)\n",
    "model.save(f\"{models_folder}/a2c_upside_vec_{env_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2aba8b4-678b-4d0d-a5dd-695937db528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_my_atari_env(env_id, n_envs=1, seed=0)\n",
    "env = VecFrameStack(env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99a65164-4e8a-447f-9753-7e6293e7f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "obs = env.reset()\n",
    "img = env.render(mode=\"rgb_array\")\n",
    "# for i in range(500):\n",
    "done = False\n",
    "# while not done:\n",
    "for _ in range(500):\n",
    "    images.append(img)\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    img = env.render(mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84406845-adaf-4595-ae8d-dca69110dda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fps = 60*4\n",
    "# dur = len(images)/fps\n",
    "dur = 30\n",
    "imageio.mimsave(f\"{gif_folder}/{env_id}_upside_vec.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], duration=dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9a8554-f546-452f-832f-c125919bc930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
